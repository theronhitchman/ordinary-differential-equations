---
layout: post
title: Curve Fitting Finale
date: 2016-09-02 13:00
---

Today I finished a presentation on how linear regression works from the point of
view of linear algebra. In the middle of all of that, we saw some really cool stuff:

  - the fundamental theorem of linear algebra
  - the four subspaces associated to a matrix
  - the transpose
  - fun facts about \\(A^T A \\): it is always square and symmetric. If \\(A\\)
  has full column rank then \\(A^T A\\) is also invertible.
  - how projection onto a subspace works
  - One of my favorite pictures, IN COLOR
  - why all of that matters for fitting a polynomial curve to data, and how it
  relates to minimizing the sum of squared errors

We computed a silly example to show things really work in practice.

<strong>Edit:</strong> [The worksheet I made in class today is here.](https://cloud.sagemath.com/projects/36700d99-c2a8-4515-86e5-c925d1af1355/files/Differential%20Equations%20Stuff/linear_regression.sagews)

### For Tuesday

Please remember that your Sublimation Model fitting paper is due at the end of the
day on Tuesday.

### For Wednesday

Go read some more about differential equations. Just an hour or so is great. It is
just important to read.
